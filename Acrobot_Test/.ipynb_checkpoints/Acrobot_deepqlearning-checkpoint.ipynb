{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import pip\n",
    "#pip.main(['install','gym'])\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, img_height, img_width):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=img_height*img_width*3, out_features=24)\n",
    "        self.fc2 = nn.Linear(in_features=24, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=3) # 3 possible actions\n",
    "         \n",
    "    def forward(self, t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\n",
    "    'Experience',\n",
    "    ('state', 'action', 'next_state', 'reward')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "        \n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * \\\n",
    "            math.exp(-1. * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions, device):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "        \n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if rate > random.random():\n",
    "            action = random.randrange(self.num_actions)\n",
    "            return torch.tensor([action]).to(self.device) # explore\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).to(self.device) # exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcrobotEnvManager():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('Acrobot-v1').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "    \n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        _, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device=self.device)\n",
    "    \n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    \n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s2\n",
    "            return s2 - s1\n",
    "        \n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    \n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    \n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2,0,1))\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self, screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        \n",
    "        # Strip off top and bottom\n",
    "        top = int(screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:, top:bottom, :]\n",
    "        return screen\n",
    "    \n",
    "    def transform_screen_data(self, screen):\n",
    "        # Convert to float, rescale, convert to tensor\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        \n",
    "        # Use torchvision package to compose image transforms\n",
    "        resize = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((40,90)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        return resize(screen).unsqueeze(0).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    \n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)\n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", \\\n",
    "         moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
    "            .mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(experiences):\n",
    "    \n",
    "    batch = Experience(*zip(*experiences))\n",
    "    \n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.reward)\n",
    "    t4 = torch.cat(batch.next_state)\n",
    "    \n",
    "    return (t1,t2,t3,t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim=1,index=actions.unsqueeze(-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_next(target_net, next_states):\n",
    "        final_state_locations = next_states.flatten(start_dim=1) \\\n",
    "            .max(dim=1)[0].eq(0).type(torch.bool)\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        values = torch.zeros(batch_size).to(QValues.device)\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 \n",
      " 100 episode moving avg: 0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "gamma = 0.999\n",
    "eps_start = 1\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.001\n",
    "target_update = 10\n",
    "memory_size = 100000\n",
    "lr = 0.001\n",
    "num_episodes = 1000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = AcrobotEnvManager(device)\n",
    "strategy = EpsilonGreedyStrategy(eps_start, eps_end, eps_decay)\n",
    "agent = Agent(strategy, em.num_actions_available(), device)\n",
    "memory = ReplayMemory(memory_size)\n",
    "\n",
    "policy_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net = DQN(em.get_screen_height(), em.get_screen_width()).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(params=policy_net.parameters(), lr=lr)\n",
    "\n",
    "episode_durations = []\n",
    "for episode in range(num_episodes):\n",
    "    em.reset()\n",
    "    state = em.get_state()\n",
    "    \n",
    "    for timestep in count():\n",
    "        action = agent.select_action(state, policy_net)\n",
    "        reward = em.take_action(action)\n",
    "        next_state = em.get_state()\n",
    "        memory.push(Experience(state, action, next_state, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size):\n",
    "            experiences = memory.sample(batch_size)\n",
    "            states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "            \n",
    "            current_q_values = QValues.get_current(policy_net, states, actions)\n",
    "            next_q_values = QValues.get_next(target_net, next_states)\n",
    "            target_q_values = (next_q_values * gamma) + rewards\n",
    "            \n",
    "            loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if em.done:\n",
    "            print(\"here\")\n",
    "            episode_durations.append(timestep)\n",
    "            plot(episode_durations, 100)\n",
    "            break\n",
    "    \n",
    "    if episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
